version: "3.7"
services:  
    # airflow LocalExecutor
    postgres:
        image: "postgres:13"
        container_name: "postgres"
        environment:
        - POSTGRES_USER=airflow
        - POSTGRES_PASSWORD=airflow
        - POSTGRES_DB=hospital
        ports:
        - "5432:5432"
        volumes:
        - ./data/postgres:/var/lib/postgresql/data

    airflow-webserver:
        image: jh111/airflow-hadoop-spark:v2
        restart: always
        environment:
            - AIRFLOW_HOME=/home/airflow
            - AIRFLOW__CORE__LOAD_EXAMPLES=False
            - AIRFLOW__CORE__dags_folder=/home/airflow/dags
        volumes:
            - ./dags:/home/airflow/dags #DAG folder
            - ./entry.sh:/home/airflow/entry.sh
        ports:
            - "7777:7777"
        entrypoint: sh /home/airflow/entry.sh
        depends_on: 
          - postgres

        #command: bash -c "sudo /etc/init.d/ssh start &&
        #                  pip install pyspark==3.2.2 &&
        #                  source ~/.profile &&
        #                  start-dfs.sh &&
        #                  start-yarn.sh &&
        #                  airflow webserver -D --port 7777 &&
        #                  airflow scheduler"

    django:
        image: jh111/django:v4
        restart: always
        ports:
        - "8181:8181"
        command: bash -c "source /venv/bin/activate &&
                          python3 /venv/src/black-dashboard-django/manage.py makemigrations &&
                          python3 /venv/src/black-dashboard-django/manage.py migrate &&
                          python3 /venv/src/black-dashboard-django/manage.py runserver 0.0.0.0:8181"
        depends_on:
         - postgres
        volumes:
        - ./venv:/venv
                   
